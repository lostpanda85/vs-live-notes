# VS Live Notes

## Monday

### Dev Ops Agent (CoPilot)

#### Local

##### Local App

* ASP.Net Blazor Front End (locally/kestrel)
* Aspire-enabled
  * Framework for C#
  * Better Refresh (F5) Experience
  * Vector DB
  * AI-Chat Web App
    * Ollama
    * Text-only, not multimodal
  * PDF links for "Source of Truth", most likely will train on it??
* Generates output with links to "Source of Truth" using a RAG pattern and Vector DB
* MCP
  * Reaches out to GitHub to take action
  * Uses natural language processing
  * Can also generate GitHub issues for feature requests

##### General

Fun Fact - DeepSeek needs 671 GB of RAM to run fully locally.

Ollama - Opensource runtime environment for AI.

Small chunks = better.

Model stays in memory until cleared, makes subsequent requests faster.

MCP servers can do a lot for agents, but need to have the correct scope. MCP provides Natural Language processing.

Cloud version of the app does pretty much the same, except computation is done in the cloud.

## Tuesday

## Wednesday

## Thursday